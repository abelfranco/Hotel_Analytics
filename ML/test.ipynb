{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo Parquet con las reseñas\n",
    "table = pq.read_table(\"../hoteles_review_estado_actualizado.parquet\")\n",
    "df = table.to_pandas()\n",
    "\n",
    "# Filtrar las reseñas con rating igual a 1\n",
    "reseñas_con_rating_1 = df[df['rating'] == 1]\n",
    "\n",
    "# Filtrar las 70 primeras reseñas con rating igual a 1\n",
    "primeras_40_reseñas = reseñas_con_rating_1.head(20)\n",
    "# Extraer las reseñas y guardarlas en un archivo de texto\n",
    "reviews = primeras_40_reseñas[\"comentario\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\USUARIO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: i, job, door, car, whole, staff, little, bad, few, auto\n",
      "Topic 2: i, place, worst, hot, water, green, days, last, stay, leak\n",
      "Topic 3: i, car, dent, insurance, contract, manager, company, location, claim, rental\n",
      "Topic 4: staff, last, i, customer, service, hotel, green, days, due, place\n",
      "Topic 5: i, hotel, groupon, smell, reservation, quote, filthy, day, phone, free\n",
      "Topic 6: office, service, customer, lines, staff, nice, taylor, easton, rd, proud\n",
      "Topic 7: rooms, pool, road, hilton, team, last, great, conditions, customers, concert\n",
      "Topic 8: i, breakfast, money, day, elevator, front, next, manager, rude, mildew\n",
      "Topic 9: hotel, floor, sheets, i, elevator, area, room, total, many, renovation\n",
      "Topic 10: i, card, day, someone, extra, hold, charge, bill, charges, time\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: inspectors non-working, ceilings/walls filthy, bathrooms/rooms filthy, towels shower, orleans second, furnishings prior, rust filthy, telephones filthy, filth unhygienic, elevator whole\n",
      "Topic 2: i disappointed, wifi fast, smell second, smell pervasive, smell bad, rates additional, rate free, positives free, kind sensitive, juices free\n",
      "Topic 3: elevator unstable, i ready, i next, message horrible, manager rude, breakfast worth, front nice, bed hard, i important, fuse next\n",
      "Topic 4: i worst, floors wet, hotel long, hotel double, groupon helpful, morning able, place negative, club/restaurant loud, attitude last, time i\n",
      "Topic 5: way many, inns past, floor only, sheets uncomfortable, middle total, machines th, i non, renovation total, hotel many, elevator due\n",
      "Topic 6: hold high, facebook several, bill same, phone next, people similar, day extra, week timely, i wrong, card lied, i sure\n",
      "Topic 7: road better, lot more, rooms last, spot same, experience queen, i few, body worst, car sloppy, stories little, staff nice\n",
      "Topic 8: dent i, car previous, company huge, road rude, copy horrible, reason i, car initial, phil assistant, page pleasant, fault due\n",
      "Topic 9: manger several, hotel tried, way little, i sleepy, drive due, times busy, danger i, refund i, right honest, client last\n",
      "Topic 10: pool green, staff great, date scary, pool black, facilities good, person rental, proud worst, service rental, attitude last, time i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\USUARIO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Descargar el paquete de datos de NLTK para el etiquetado gramatical\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Crear una función para filtrar las palabras por categoría gramatical y formar pares sustantivo-adjetivo\n",
    "def filter_and_pair_by_pos(text, pos_tags=['NN', 'NNS', 'JJ']):\n",
    "    tagged_words = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    pairs = []\n",
    "    noun = None\n",
    "    for word, pos in tagged_words:\n",
    "        if pos.startswith('N'):\n",
    "            noun = word\n",
    "        elif pos.startswith('J') and noun:\n",
    "            pairs.append(f\"{noun} {word}\")\n",
    "            noun = None\n",
    "    return pairs\n",
    "\n",
    "# Crear una matriz de términos-documentos usando CountVectorizer y filtrar las palabras por sustantivo y adjetivo\n",
    "vectorizer = CountVectorizer(tokenizer=lambda text: filter_and_pair_by_pos(text, pos_tags=['NN', 'NNS', 'JJ']))\n",
    "X = vectorizer.fit_transform(primeras_40_reseñas[\"comentario\"])\n",
    "\n",
    "# Aplicar LDA para identificar los temas de quejas\n",
    "num_topics = 10\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Obtener los términos más importantes por cada tema\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "top_pairs_by_topic = {}\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    top_pairs_idx = topic.argsort()[:-11:-1]\n",
    "    top_pairs_by_topic[topic_idx + 1] = [feature_names[i] for i in top_pairs_idx]\n",
    "\n",
    "# Imprimir los pares sustantivo-adjetivo más importantes por cada tema\n",
    "for topic, top_pairs in top_pairs_by_topic.items():\n",
    "    print(f\"Topic {topic}: {', '.join(top_pairs)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
